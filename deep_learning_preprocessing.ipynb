{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fall Detection using SisFall Dataset\n",
    "Daniela Dias, nMec 98039"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc0d4d192d886215"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:42:57.581076Z",
     "start_time": "2025-05-01T19:42:55.711546Z"
    }
   },
   "id": "671e33acf94d3048",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Avoiding Subject Bias in Train-Test Split\n",
    "\n",
    "When working with the SisFall dataset (or any dataset where multiple recordings come from the same individuals), it is essential to avoid data leakage caused by random sample splitting. \n",
    "\n",
    "If we randomly split the dataset into training and testing sets, we risk placing samples from the same subject in both sets. This introduces what is known as \"subject bias\" — the model can inadvertently learn personal characteristics or movement patterns of specific individuals rather than learning to generalize fall detection across new, unseen people. This would artificially inflate evaluation metrics (such as accuracy and F1-score), because the model is partially memorizing rather than generalizing.\n",
    "\n",
    "To address this, we use a subject-wise splitting strategy:  \n",
    "- We first extract the list of unique subjects.  \n",
    "- Then we split these subjects into train and test groups.  \n",
    "- Finally, we assign samples based on the subject to which they belong.\n",
    "\n",
    "This ensures that the model is evaluated on entirely unseen individuals, simulating real-world scenarios where fall detection must work for new users. It leads to more honest and generalizable performance metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c5745d4336011ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Learning Preprocessing\n",
    "\n",
    "This pipeline prepares raw time-series sensor data for deep learning models such as CNNs or LSTMs.\n",
    "\n",
    "1. Raw sensor data is segmented into fixed-length overlapping windows (e.g., 2 seconds = 400 samples at 200 Hz).\n",
    "    - Each window is treated as a single sample.\n",
    "   - The overlap can be adjusted (e.g., 50% overlap).\n",
    "2. Each window is converted into a 3D tensor: (number of samples, window length, number of channels).\n",
    "    - For example, with 400-sample windows and 9 channels (3 sensors × 3 axes), the shape should be (N, 400, 9).\n",
    "3. Labels are assigned to each window based on the most frequent class label within the window.\n",
    "4. Input windows are normalized using z-score standardization based on the training set.\n",
    "5. Subject-wise splitting is used to ensure no overlap of subjects between training and testing sets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d11001580ab7f12"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the dataset from CSV file\n",
    "sisfall_data = pd.read_csv('sisfall_reduced_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:10.140829Z",
     "start_time": "2025-05-01T19:42:57.582088Z"
    }
   },
   "id": "948d6a316abc4edb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def segment_data(df, window_size, overlap):\n",
    "    # Calculate the step size based on the window size and overlap\n",
    "    step = int(window_size * (1 - overlap))\n",
    "\n",
    "    features, labels = [], []\n",
    "    # Iterate through each sample\n",
    "    for i in range(0, len(df) - window_size + 1, step):\n",
    "        \n",
    "        # Extract the window of data\n",
    "        window = df.iloc[i:i + window_size, :-1].values     # Exclude the label column\n",
    "        label = df.iloc[i:i + window_size, -1].mode()[0]    # Get the most common label in the window\n",
    "\n",
    "        # Append the window and label to the lists\n",
    "        features.append(window)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(features), np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:10.162039Z",
     "start_time": "2025-05-01T19:43:10.142837Z"
    }
   },
   "id": "4aa675ece726bae0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_for_deep_learning(df, window_size=400, overlap=0.5):\n",
    "    # Extract unique subjects\n",
    "    subjects = df['subject'].unique()\n",
    "\n",
    "    # Subject-wise split\n",
    "    train_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assign samples based on subject\n",
    "    train_data = df[df['subject'].isin(train_subjects)]\n",
    "    test_data = df[df['subject'].isin(test_subjects)]\n",
    "\n",
    "    # Segment data into windows\n",
    "    X_train, y_train = segment_data(train_data, window_size, overlap)\n",
    "    X_test, y_test = segment_data(test_data, window_size, overlap)\n",
    "\n",
    "    # Normalize using training statistics\n",
    "    mean = X_train.mean(axis=(0, 1), keepdims=True)\n",
    "    std = X_train.std(axis=(0, 1), keepdims=True)\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    # Convert labels to numeric\n",
    "    y_train = pd.Series(y_train).map({'adl': 0, 'fall': 1})\n",
    "    y_test = pd.Series(y_test).map({'adl': 0, 'fall': 1})\n",
    "    \n",
    "    # Convert to dataframes\n",
    "    X_train = pd.DataFrame(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_test = pd.DataFrame(X_test.reshape(X_test.shape[0], -1))\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:10.173586Z",
     "start_time": "2025-05-01T19:43:10.163562Z"
    }
   },
   "id": "4809cd21ca4f3c2e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train, X_test, y_train, y_test = preprocess_for_deep_learning(sisfall_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-05-01T19:43:10.177116Z"
    }
   },
   "id": "a9748eba4d99f46a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check the shape of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a32be34713284722"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the preprocessed dataset to CSV files\n",
    "X_train.to_csv('deep_learning/X_train.csv', index=False)\n",
    "X_test.to_csv('deep_learning/X_test.csv', index=False)\n",
    "y_train.to_csv('deep_learning/y_train.csv', index=False)\n",
    "y_test.to_csv('deep_learning/y_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2bdf2f170ca05ab9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
