{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fall Detection using SisFall Dataset\n",
    "Daniela Dias, nMec 98039"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d88bef153d2822"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:46:51.613142Z",
     "start_time": "2025-05-02T21:46:51.586785Z"
    }
   },
   "id": "bf9eb9243621cfd5",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Avoiding Subject Bias in Train-Test Split\n",
    "\n",
    "When working with the SisFall dataset (or any dataset where multiple recordings come from the same individuals), it is essential to avoid data leakage caused by random sample splitting. \n",
    "\n",
    "If we randomly split the dataset into training and testing sets, we risk placing samples from the same subject in both sets. This introduces what is known as \"subject bias\" â€” the model can inadvertently learn personal characteristics or movement patterns of specific individuals rather than learning to generalize fall detection across new, unseen people. This would artificially inflate evaluation metrics (such as accuracy and F1-score), because the model is partially memorizing rather than generalizing.\n",
    "\n",
    "To address this, we use a subject-wise splitting strategy:  \n",
    "- We first extract the list of unique subjects.  \n",
    "- Then we split these subjects into train and test groups.  \n",
    "- Finally, we assign samples based on the subject to which they belong.\n",
    "\n",
    "This ensures that the model is evaluated on entirely unseen individuals, simulating real-world scenarios where fall detection must work for new users. It leads to more honest and generalizable performance metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6660eb907352464b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traditional Machine Learning Preprocessing\n",
    "\n",
    "The preprocessing pipeline for traditional machine learning begins by converting raw sensor data into numerical features that summarize activity windows.\n",
    "\n",
    "1. Raw signal data is segmented into overlapping windows of fixed length (e.g., 2 seconds = 400 samples at 200 Hz).\n",
    "   - Each window is treated as a single sample.\n",
    "   - The overlap can be adjusted (e.g., 25% overlap).\n",
    "2. For each window, both time-domain and frequency-domain features are extracted:\n",
    "   - Time-domain: mean, standard deviation, min, max, median, skewness, kurtosis.\n",
    "   - Frequency-domain: FFT mean, standard deviation, max, and energy.\n",
    "3. Each window is labeled based on the most frequent label within it.\n",
    "4. Features are normalized using z-score standardization based on the training set.\n",
    "5. SMOTE (Synthetic Minority Oversampling Technique) is applied to the training data to address class imbalance between falls and ADLs.\n",
    "6. Subject-wise splitting is used to ensure no overlap of subjects between training and testing sets.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce4ee760b0a212e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the dataset from CSV file\n",
    "sisfall_data = pd.read_csv('../reduced_sisfall_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:46:56.296145Z",
     "start_time": "2025-05-02T21:46:51.616472Z"
    }
   },
   "id": "84b81af19e978229",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Feature extraction function with frequency-domain features\n",
    "def extract_features(df, window_size=400, overlap=0.25, variance_threshold=0.3):\n",
    "    # Calculate the step size based on the window size and overlap\n",
    "    step = int(window_size * (1 - overlap))\n",
    "    \n",
    "    # Obtain the sensor columns\n",
    "    sensor_cols = df.columns[:-3]  # Exclude label, filename, subject\n",
    "\n",
    "    # Generate feature names (only once)\n",
    "    feature_names = []\n",
    "    for col in sensor_cols:\n",
    "        feature_names.extend([\n",
    "            f'{col}_mean', f'{col}_std', f'{col}_min', f'{col}_max', f'{col}_median', f'{col}_skew', f'{col}_kurt',\n",
    "            f'{col}_fft_mean', f'{col}_fft_std', f'{col}_fft_max', f'{col}_fft_energy'\n",
    "        ])\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for filename, group in df.groupby('filename'):\n",
    "        group = group.reset_index(drop=True)\n",
    "        for start in range(0, len(group) - window_size + 1, step):\n",
    "            window = group.iloc[start:start + window_size]\n",
    "            feature_vector = []\n",
    "\n",
    "            # Compute average standard deviation across all channels\n",
    "            mean_std = np.mean([window[col].std() for col in sensor_cols])\n",
    "            if mean_std < variance_threshold:\n",
    "                continue  # Skip this window\n",
    "\n",
    "            for col in sensor_cols:\n",
    "                data = pd.to_numeric(window[col], errors='coerce').fillna(0).values\n",
    "\n",
    "                # Time-domain features\n",
    "                feature_vector.extend([\n",
    "                    data.mean(), data.std(), data.min(), data.max(),\n",
    "                    np.median(data), skew(data), kurtosis(data)\n",
    "                ])\n",
    "\n",
    "                # Frequency-domain features\n",
    "                fft_values = np.abs(fft(data))\n",
    "                feature_vector.extend([\n",
    "                    fft_values.mean(), fft_values.std(), fft_values.max(),\n",
    "                    np.sum(fft_values ** 2) / len(fft_values)\n",
    "                ])\n",
    "\n",
    "            label = window['label'].mode().iloc[0]\n",
    "            all_features.append(feature_vector)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return np.array(all_features), np.array(all_labels), feature_names\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:46:56.331757Z",
     "start_time": "2025-05-02T21:46:56.299443Z"
    }
   },
   "id": "b51e5edfebfbfdea",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preprocessing function to handle class imbalance and scaling\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    # Extract unique subjects\n",
    "    subjects = df['subject'].unique()\n",
    "    \n",
    "    # Subject-wise split\n",
    "    train_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assign samples based on subject\n",
    "    train_data = df[df['subject'].isin(train_subjects)]\n",
    "    test_data = df[df['subject'].isin(test_subjects)]\n",
    "\n",
    "    # Extract features from training and testing data\n",
    "    X_train, y_train, feature_names = extract_features(train_data)\n",
    "    X_test, y_test, _ = extract_features(test_data)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Add SMOTE for handling class imbalance\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Convert labels to binary format\n",
    "    y_train_balanced = pd.Series(y_train_balanced).map({'adl': 0, 'fall': 1})\n",
    "    y_test = pd.Series(y_test).map({'adl': 0, 'fall': 1})\n",
    "\n",
    "    # Convert to DataFrame for easier handling\n",
    "    X_train_balanced = pd.DataFrame(X_train_balanced, columns=feature_names)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "    y_train_balanced = pd.DataFrame(y_train_balanced, columns=['label'])\n",
    "    y_test = pd.DataFrame(y_test, columns=['label'])\n",
    "\n",
    "    return X_train_balanced, y_train_balanced, X_test_scaled, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:46:56.344630Z",
     "start_time": "2025-05-02T21:46:56.335042Z"
    }
   },
   "id": "326da2a1e93ce0f3",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "X_train, y_train, X_test, y_test = preprocess_data(sisfall_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:48:54.968584Z",
     "start_time": "2025-05-02T21:46:56.347949Z"
    }
   },
   "id": "51ac065b87f15953",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((10960, 99), (10960, 1), (1870, 99), (1870, 1))"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the training and testing sets\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:48:54.981237Z",
     "start_time": "2025-05-02T21:48:54.970790Z"
    }
   },
   "id": "1b5b9609104f90ec",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the preprocessed dataset to CSV files\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T21:48:56.885099Z",
     "start_time": "2025-05-02T21:48:54.983499Z"
    }
   },
   "id": "cdbaafb8ccf52a26",
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
